import numpy as np

def f(x):
    x1, x2 = x
    return 7*x1**2 + 2*x1*x2 + 5*x2**2 + x1 - 10*x2

def grad_f(x):
    x1, x2 = x
    df_dx1 = 14*x1 + 2*x2 + 1
    df_dx2 = 2*x1 + 10*x2 - 10
    return np.array([df_dx1, df_dx2])

def steepest_descent():
    x = np.array([0.0, 0.0])  # Начальное значение x
    alpha = 0.01  # Размер шага
    precision = 0.0001  # Точность
    max_iterations = 1000  # Максимальное количество итераций

    for i in range(max_iterations):
        gradient = grad_f(x)
        x_new = x - alpha * gradient

        if np.linalg.norm(gradient) < precision:
            break

        x = x_new

    print("Оптимальное значение x1:", x[0])
    print("Оптимальное значение x2:", x[1])
    print("Значение функции в оптимальной точке:", f(x))

steepest_descent()
